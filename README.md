Demo: https://drive.google.com/file/d/1_0B85GjBt7xw6mqklpSq_EvvbcCKRwN8/view?uuspdrive_link

Designed AI agent evaluation benchmark using LLM-as-judge (Gemini) to score multi-agent conversations by implementing AutoGen GroupChat with custom routing and deploying parallel Harbor execution in Daytona containers.
